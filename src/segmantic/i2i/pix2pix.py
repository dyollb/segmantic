from pathlib import Path

import torch
import torch.nn.functional as F
from monai.data import CacheDataset
from monai.transforms import (
    Compose,
    CropForegroundd,
    EnsureChannelFirstd,
    EnsureTyped,
    LoadImaged,
    NormalizeIntensityd,
    Orientationd,
    RandWeightedCropd,
)
from pytorch_lightning import LightningModule, Trainer
from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar
from torch import nn
from torch.utils.data import DataLoader
from torchmetrics.functional import accuracy
from torchmetrics.functional import peak_signal_noise_ratio as psnr
from torchmetrics.functional import scale_invariant_signal_noise_ratio as ssim

from segmantic.seg.dataset import PairedDataSet

from .pix2pix_nets import Generator, PatchGAN

GENERATOR_IDX = 0
DISCRIMINATOR_IDX = 0


def _weights_init(m):
    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Conv3d, nn.ConvTranspose3d)):
        torch.nn.init.normal_(m.weight, 0.0, 0.02)
    if isinstance(m, (nn.BatchNorm2d, nn.BatchNorm3d)):
        torch.nn.init.normal_(m.weight, 0.0, 0.02)
        torch.nn.init.constant_(m.bias, 0)


class Pix2Pix(LightningModule):
    def __init__(
        self,
        spatial_dims: int,
        in_channels: int,
        out_channels: int,
        lambda_recon: float = 200,
        generator_lr: float = 1e-3,
        discriminator_lr: float = 1e-6,
        weight_decay: float = 1e-5,
        lr_scheduler_T_0: float = 1e3,
        lr_scheduler_T_mult: float = 2,
        clip_generator_prediction=True,
    ):
        """
        Pix2Pix model

        Adapted from https://www.aryan.no/post/pix2pix/pix2pix/
        """
        super().__init__()
        self.save_hyperparameters()

        self.lambda_recon = lambda_recon
        self.generator_lr = generator_lr
        self.discriminator_lr = discriminator_lr
        self.weight_decay = weight_decay
        self.lr_scheduler_T_0 = lr_scheduler_T_0
        self.lr_scheduler_T_mult = lr_scheduler_T_mult
        self.clip_generator_prediction = clip_generator_prediction

        self.generator = Generator(spatial_dims, in_channels, out_channels)
        self.discriminator = PatchGAN(spatial_dims, in_channels + out_channels)

        # intializing weights
        self.generator = self.generator.apply(_weights_init)
        self.discriminator = self.discriminator.apply(_weights_init)

    def generator_loss(
        self, prediction_image, target_image, prediction_label, target_label
    ):
        """
        Generator loss (a combination of):
            1 - Binary Cross-Entropy
                Between predicted labels (generated by the discriminator) and target labels which is all 1s
            2 - L1 / Mean Absolute Error (weighted by lambda)
                Between generated image and target image
            3 - L2 / Mean Squared Error (weighted by lambda)
                Between generated image and target image
        """
        bce_loss = F.binary_cross_entropy(prediction_label, target_label)
        l1_loss = F.l1_loss(prediction_image, target_image)
        mse_loss = F.mse_loss(prediction_image, target_image)
        return bce_loss, l1_loss, mse_loss

    def discriminator_loss(self, prediction_label, target_label):
        """
        Discriminator loss:
            1 - Binary Cross-Entropy
                Between predicted labels (generated by the discriminator) and target labels
                The target would be all 0s if the input of the discriminator is the generated image (generator)
                The target would be all 1s if the input of the discriminator is the target image (dataloader)
        """
        bce_loss = F.binary_cross_entropy(prediction_label, target_label)
        return bce_loss

    def configure_optimizers(self):
        """
        Using Adam optimizer for both generator and discriminator including L2 regularization
        Both would have different initial learning rates
        Stochastic Gradient Descent with Warm Restarts is also added as learning scheduler (https://arxiv.org/abs/1608.03983)
        """
        # Optimizers
        generator_optimizer = torch.optim.Adam(
            self.generator.parameters(),
            lr=self.generator_lr,
            weight_decay=self.weight_decay,
        )
        discriminator_optimizer = torch.optim.Adam(
            self.discriminator.parameters(),
            lr=self.discriminator_lr,
            weight_decay=self.weight_decay,
        )

        # Learning Scheduler
        generator_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            generator_optimizer,
            T_0=self.lr_scheduler_T_0,
            T_mult=self.lr_scheduler_T_mult,
        )
        discriminator_lr_scheduler = (
            torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
                discriminator_optimizer,
                T_0=self.lr_scheduler_T_0,
                T_mult=self.lr_scheduler_T_mult,
            )
        )
        return [generator_optimizer, discriminator_optimizer], [
            generator_lr_scheduler,
            discriminator_lr_scheduler,
        ]

    def generator_step(self, image, target):
        generator_prediction = self.generator(image)
        if self.clip_generator_prediction:
            generator_prediction = torch.clip(generator_prediction, 0, 1)

        discriminator_prediction_fake = self.discriminator(
            torch.cat((image, generator_prediction), dim=1)
        )

        generator_bce_loss, generator_l1_loss, generator_mse_loss = self.generator_loss(
            generator_prediction,
            target,
            discriminator_prediction_fake,
            torch.ones_like(discriminator_prediction_fake),
        )
        return (
            generator_bce_loss
            + (generator_l1_loss * self.lambda_recon)
            + (generator_mse_loss * self.lambda_recon)
        )

    def discriminator_step(self, image, target):
        generator_prediction = self.generator(image)
        if self.clip_generator_prediction:
            generator_prediction = torch.clip(generator_prediction, 0, 1)

        discriminator_prediction_real = self.discriminator(
            torch.cat((image, target), dim=1)
        )
        discriminator_prediction_fake = self.discriminator(
            torch.cat((image, generator_prediction), dim=1)
        )

        discriminator_label_real = self.discriminator_loss(
            discriminator_prediction_real,
            torch.ones_like(discriminator_prediction_real),
        )
        discriminator_label_fake = self.discriminator_loss(
            discriminator_prediction_fake,
            torch.zeros_like(discriminator_prediction_fake),
        )
        return discriminator_label_real + discriminator_label_fake

    def training_step(self, batch, batch_idx, optimizer_idx):
        image, target = batch

        loss = None

        if optimizer_idx == GENERATOR_IDX:
            loss = self.generator_step(image, target)
        elif optimizer_idx == DISCRIMINATOR_IDX:
            loss = self.discriminator_step(image, target)

        return loss

    def validation_step(self, batch, batch_idx):
        image, target = batch

        # Generator Feed-Forward
        generator_prediction = self.generator(image)
        if self.clip_generator_prediction:
            generator_prediction = torch.clip(generator_prediction, 0, 1)

        # Generator Metrics
        generator_psnr = psnr(generator_prediction, target)
        generator_ssim = ssim(generator_prediction, target)
        discriminator_prediction_fake = self.discriminator(
            torch.cat((image, generator_prediction), dim=1)
        )
        generator_accuracy = accuracy(
            discriminator_prediction_fake,
            torch.ones_like(discriminator_prediction_fake, dtype=torch.int32),
        )

        # Discriminator Feed-Forward
        discriminator_prediction_real = self.discriminator(
            torch.cat((image, target), dim=1)
        )
        discriminator_prediction_fake = self.discriminator(
            torch.cat((image, generator_prediction), dim=1)
        )
        # Discriminator Metrics
        discriminator_accuracy = accuracy(
            discriminator_prediction_real,
            torch.ones_like(discriminator_prediction_real, dtype=torch.int32),
        ) + accuracy(
            discriminator_prediction_fake,
            torch.zeros_like(discriminator_prediction_fake, dtype=torch.int32),
        )

        # Progressbar and Logging
        metrics = {
            "val_g_psnr": generator_psnr,
            "val_g_ssim": generator_ssim,
            "val_g_accuracy": generator_accuracy,
            "val_d_accuracy": discriminator_accuracy,
        }

        self.log_dict(metrics, prog_bar=True)
        return metrics


def train(
    source_dir: Path,
    target_dir: Path,
    output_dir: Path,
    max_epochs: int = 600,
    train_batch_size: int = 32,
    val_batch_size: int = 16,
):

    model = Pix2Pix(spatial_dims=2, in_channels=2, out_channels=1)
    print(model(torch.randn(1, 2, 256, 256)).shape)

    checkpoint_callback = ModelCheckpoint(
        dirpath=output_dir,
        filename="{epoch}-{disc_loss:.2f}-{gen_loss:.2f}",
        monitor="disc_loss",
        mode="min",
        save_top_k=3,
    )

    progress = TQDMProgressBar(refresh_rate=10)

    # https://www.aryan.no/post/pix2pix/pix2pix/
    # epoch_inference_callback = EpochInference(test_dataloader)

    keys = ["source", "target"]
    transforms = Compose(
        [
            LoadImaged(keys=keys, reader="itkreader"),
            EnsureChannelFirstd(keys=keys),
            Orientationd(keys=keys, axcodes="RAS"),
            NormalizeIntensityd(keys=keys, nonzero=True, channel_wise=True),
            CropForegroundd(keys=keys, source_key="source"),
            RandWeightedCropd(keys=keys, spatial_size=[224, 224]),
            EnsureTyped(keys=keys),
        ]
    )

    dataset = PairedDataSet(input_dir=source_dir, output_dir=target_dir)

    train_dataset = CacheDataset(data=dataset.training_files(), transform=transforms)
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=train_batch_size,
        num_workers=0,
        shuffle=True,
        drop_last=True,
    )
    val_dataset = CacheDataset(data=dataset.validation_files(), transform=transforms)
    val_dataloader = DataLoader(
        val_dataset,
        batch_size=val_batch_size,
        num_workers=0,
        shuffle=False,
    )

    trainer = Trainer(
        gpus=1,
        max_epochs=max_epochs,
        val_check_interval=0.5,
        default_root_dir="./pix2pix/",
        callbacks=[checkpoint_callback, progress],
    )
    trainer.fit(model, train_dataloader, val_dataloader)
